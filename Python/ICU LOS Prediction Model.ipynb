{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7cbc32f",
      "metadata": {
        "id": "d7cbc32f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import math\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot\n",
        "from scipy.stats import uniform, randint\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Model and performance evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from joblib import dump, load\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.metrics import auc, average_precision_score, precision_recall_curve\n",
        "\n",
        "# Hyperparameter tuninghCV\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from hyperopt import tpe, STATUS_OK, Trials, hp, fmin, STATUS_OK, space_eval\n",
        "from xgboost import plot_importance\n",
        "\n",
        "# Data imputation\n",
        "from imblearn.over_sampling import SMOTE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d09f2a8f",
      "metadata": {
        "id": "d09f2a8f"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab85f41b",
      "metadata": {
        "id": "ab85f41b"
      },
      "source": [
        "#### 1) Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "784aba62",
      "metadata": {
        "id": "784aba62"
      },
      "outputs": [],
      "source": [
        "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
        "    confusion = confusion_matrix(y_test, pred)\n",
        "    accuracy = accuracy_score(y_test , pred)\n",
        "    precision = precision_score(y_test , pred)\n",
        "    recall = recall_score(y_test , pred)\n",
        "    f1 = f1_score(y_test,pred)\n",
        "\n",
        "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
        "    precision_, recall_, thr = precision_recall_curve(y_test, pred_proba)\n",
        "    pr_auc = auc(recall_, precision_)\n",
        "\n",
        "    result = '{0:.4f}, {1:.4f}, {2:.4f}, {3:.4f}, {4:.4f}, {5:.4f}'.format(accuracy, precision, recall, f1, roc_auc, pr_auc)\n",
        "\n",
        "    return confusion, result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca25e9c",
      "metadata": {
        "id": "eca25e9c"
      },
      "source": [
        "#### 2) Plot AUROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfba059f",
      "metadata": {
        "id": "bfba059f"
      },
      "outputs": [],
      "source": [
        "def roc_curve_plot(y_test, opted_predict_prob,label_name):\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, opted_predict_prob)\n",
        "\n",
        "    plt.plot(fpr, tpr, label = label_name)\n",
        "    plt.plot([0,1], 'k--')\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.title(\"AUROC\")\n",
        "    plt.legend(fontsize=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa2edb9c",
      "metadata": {
        "id": "aa2edb9c"
      },
      "source": [
        "#### 3) Plot AUPRC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea1f838",
      "metadata": {
        "id": "3ea1f838"
      },
      "outputs": [],
      "source": [
        "def plot_pr_curve(recall, precision,label_name):\n",
        "    pyplot.plot([0, 1], 'k--')\n",
        "    pyplot.plot(recall, precision, label=label_name)\n",
        "\n",
        "    pyplot.xlabel('Recall')\n",
        "    pyplot.ylabel('Precision')\n",
        "    plt.title(\"AUPRC\")\n",
        "    pyplot.legend(fontsize=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e67af3e",
      "metadata": {
        "id": "4e67af3e"
      },
      "source": [
        "#### 4) Preprocess_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb31626b",
      "metadata": {
        "id": "fb31626b"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(input, output):\n",
        "\n",
        "    features = pd.read_excel(input)\n",
        "    label = pd.read_excel(output)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, label,\n",
        "                                                    test_size=0.2, random_state=1)\n",
        "\n",
        "\n",
        "    y_train = np.ravel(y_train)\n",
        "    y_test = np.ravel(y_test)\n",
        "\n",
        "    # imputating train_data\n",
        "    smote = SMOTE(random_state=0)\n",
        "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16f47ff",
      "metadata": {
        "id": "f16f47ff"
      },
      "source": [
        "#### 5) Plot_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Btn7onN8seQ3",
      "metadata": {
        "id": "Btn7onN8seQ3"
      },
      "outputs": [],
      "source": [
        "def plot_curve(input, output, curve, y_test, opted_predict_prob):\n",
        "\n",
        "    # set label\n",
        "    in_ = re.sub(r'[^0-9]', '', input)\n",
        "    out_ = re.sub(r'[^0-9]', '', output)\n",
        "    in_ = int(in_)\n",
        "\n",
        "    # plot ROCAUC\n",
        "    if curve == 'roc':\n",
        "        roc_auc = round(roc_auc_score(y_test, opted_predict_prob), 3)\n",
        "\n",
        "        label = f\"{in_-2}~{in_} Hours since ICU admission, {curve.upper()}_ROCAUC: {roc_auc}\"\n",
        "        roc_curve_plot(y_test, opted_predict_prob, label_name = label)\n",
        "\n",
        "    # plot PRAUC\n",
        "    elif curve == 'pr':\n",
        "        precision, recall, thresholds = precision_recall_curve(y_test, opted_predict_prob)\n",
        "        pr_auc = round(auc(recall, precision),3)\n",
        "        label = f\"{in_-2}~{in_} Hours since ICU admission, {curve.upper()}_PRAUC: {pr_auc}\"\n",
        "        plot_pr_curve(recall, precision, label_name=label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NU3kwWcptJNl",
      "metadata": {
        "id": "NU3kwWcptJNl"
      },
      "outputs": [],
      "source": [
        "def plot_curve_(input, output, curve, y_test, opted_predict_prob, model_name):\n",
        "\n",
        "    # set label\n",
        "    in_ = re.sub(r'[^0-9]', '', input)\n",
        "    out_ = re.sub(r'[^0-9]', '', output)\n",
        "\n",
        "    # plot plot ROCAUC\n",
        "    if curve == 'roc':\n",
        "        roc_auc = round(roc_auc_score(y_test, opted_predict_prob), 3)\n",
        "        label = f\"{model_name}, {curve.upper()}_ROCAUC: {roc_auc}\"\n",
        "        roc_curve_plot(y_test, opted_predict_prob, label_name = label)\n",
        "\n",
        "    # plot PRAUC\n",
        "    elif curve == 'pr':\n",
        "        precision, recall, thresholds = precision_recall_curve(y_test, opted_predict_prob)\n",
        "        pr_auc = round(auc(recall, precision),3)\n",
        "        label = f\"{model_name}, {curve.upper()}_PRAUC: {pr_auc}\"\n",
        "        plot_pr_curve(recall, precision, label_name=label)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4006f3e4",
      "metadata": {
        "id": "4006f3e4"
      },
      "source": [
        "#### 6) Train & Calibrate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad1fd50b",
      "metadata": {
        "id": "ad1fd50b"
      },
      "outputs": [],
      "source": [
        "def train_and_calibrate_model(name, model, param, X_train, y_train, X_test, y_test, input, output):\n",
        "    in_ = re.sub(r'[^0-9]', '', input)\n",
        "    out_ = re.sub(r'[^0-9]', '', output)\n",
        "\n",
        "    # random search\n",
        "    scoring = ['roc_auc']\n",
        "\n",
        "    kfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
        "\n",
        "    random_search = RandomizedSearchCV(estimator=model,\n",
        "                           param_distributions=param,\n",
        "                           n_iter=48,\n",
        "                           scoring=scoring,\n",
        "                           refit='roc_auc',\n",
        "                           n_jobs=-1,\n",
        "                           cv=kfold,\n",
        "                           verbose=0)\n",
        "\n",
        "    random_result = random_search.fit(X_train, y_train)\n",
        "\n",
        "    # save dump file\n",
        "    dump(random_search, f'./trained/{name}_matrix_trained_{in_}hr_{out_}hr.joblib')\n",
        "    print(f\"save matrix: {name}_matrix_trained_{in_}hr_{out_}hr.joblib\")\n",
        "\n",
        "    opted_predict = random_search.predict(X_test)\n",
        "    opted_predict_prob = random_search.predict_proba(X_test)[:,1]\n",
        "\n",
        "    return opted_predict, opted_predict_prob"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "910a9487",
      "metadata": {
        "id": "910a9487"
      },
      "source": [
        "#### 7) Execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19554215",
      "metadata": {
        "id": "19554215"
      },
      "outputs": [],
      "source": [
        "def execute(dir_input, dir_output, n_fold, imputation, curve, name):\n",
        "    i = 0\n",
        "    total = len(dir_input)*len(dir_output)\n",
        "    df_result = pd.DataFrame(columns = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"ROC AUC\", \"PR AUC\"])\n",
        "\n",
        "    models = {'LR': LR_model,\n",
        "                      'DT': DT_model,\n",
        "                      'RF': RF_model,\n",
        "                      'XGB': XGB_model,\n",
        "                      'KNN': KNN_model,\n",
        "                      'ANN': ANN_model,\n",
        "                      'SVM': SVM_model\n",
        "             }\n",
        "\n",
        "    model = models[name]\n",
        "\n",
        "    for output in dir_output:\n",
        "        out_ = re.sub(r'[^0-9]', '', output)\n",
        "        idx = {'Accuracy': f'{out_}hr'}\n",
        "        df_result = df_result.append(idx, ignore_index=True)\n",
        "\n",
        "        for input in dir_input:\n",
        "\n",
        "            in_ = re.sub(r'[^0-9]', '', input)\n",
        "            print(f\"{i/total*100}% processing..\")\n",
        "\n",
        "            ## Run\n",
        "            confusion, result = model(name, input, output, n_fold, curve, 1)\n",
        "\n",
        "            ## post-process results from model\n",
        "            dic = {}\n",
        "            temp = result.split(', ')\n",
        "\n",
        "            index = 0\n",
        "            for key in df_result.keys():\n",
        "                dic[key] = temp[index]\n",
        "                index += 1\n",
        "\n",
        "            df_result = df_result.append(dic, ignore_index=True)\n",
        "            plt.savefig(f'./result_graph/{name}_{imputation}_{curve}_curve_{out_}hr.png', dpi=300)\n",
        "            i = i + 1\n",
        "\n",
        "        plt.cla()\n",
        "\n",
        "        # export\n",
        "        df_result.to_csv(f'./result_csv/result_{name}_{imputation}_prolonged.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daf9c9a3",
      "metadata": {
        "id": "daf9c9a3"
      },
      "outputs": [],
      "source": [
        "## 모델별 비교 목적\n",
        "def execute_(input_path, output_path, n_fold, imputation, curve, list_models):\n",
        "\n",
        "    models = {'LR': LR_model,\n",
        "                      'DT': DT_model,\n",
        "                      'RF': RF_model,\n",
        "                      'KNN': KNN_model,\n",
        "                      'XGB': XGB_model,\n",
        "                      'SVM': SVM_model\n",
        "             }\n",
        "\n",
        "\n",
        "    in_ = re.sub(r'[^0-9]', '', input_path)\n",
        "    out_ = re.sub(r'[^0-9]', '', output_path)\n",
        "\n",
        "    if 'ANN' in list_models:\n",
        "      ANN_model(input_path, output_path, n_fold, curve)\n",
        "      plt.savefig(f'./result_graph/ALL_{imputation}_{curve}_curve_{in_}hr.png', dpi=300)\n",
        "      models.pop(models.index('ANN'))\n",
        "\n",
        "    total = len(list_models)\n",
        "\n",
        "    i = 0\n",
        "    for name in list_models:\n",
        "        model = models[name]\n",
        "\n",
        "        print(f\"{i/total*100}% processing..\")\n",
        "\n",
        "        ## Run\n",
        "        confusion, result = model(name, input_path, output_path, n_fold, curve, 2)\n",
        "\n",
        "        plt.savefig(f'./result_graph/ALL_{imputation}_{curve}_curve_{in_}hr_{out_}hr.png', dpi=300)\n",
        "\n",
        "        i = i + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6d77a9a",
      "metadata": {
        "id": "b6d77a9a"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d1f403",
      "metadata": {
        "id": "77d1f403"
      },
      "source": [
        "#### 1) Logistic Regeression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "284b621a",
      "metadata": {
        "id": "284b621a"
      },
      "outputs": [],
      "source": [
        "def LR_model(name, input, output, n_fold, curve, mode):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(input, output)\n",
        "\n",
        "    ## model\n",
        "    model = LogisticRegression(random_state=1, max_iter=2000)\n",
        "\n",
        "    ## optimizing hyper-param for model\n",
        "    param = {\n",
        "        'penalty': ['l1','l2'],\n",
        "        'dual': [True, False],\n",
        "        'tol': [0.0001],\n",
        "        'C': [1],\n",
        "        'fit_intercept': [True, False],\n",
        "        'intercept_scaling': [1],\n",
        "        'class_weight': [1, 'balanced'],\n",
        "        'random_state': [0],\n",
        "        'solver': ['newton-cg','lbfgs','liblinear','sag','saga'],\n",
        "        'max_iter': [100],\n",
        "        'multi_class': ['ovr','multinomial','auto'],\n",
        "        'verbose': [0],\n",
        "        'warm_start': [True, False],\n",
        "        'n_jobs': [None],\n",
        "        'l1_ratio': [None]\n",
        "    }\n",
        "\n",
        "    opted_predict, opted_predict_prob = train_and_calibrate_model(name, model, param, X_train, y_train, X_test, y_test, input, output)\n",
        "\n",
        "    ## Ploting curve\n",
        "    if mode = 1:\n",
        "      plot_curve(input, output, curve, y_test, opted_predict_prob)\n",
        "    elif mode = 2:\n",
        "      plot_curve_(input, output, curve, y_test, opted_predict_prob, name)\n",
        "\n",
        "    ## Get performance metrics\n",
        "    temp_comfusion, temp_result = get_clf_eval(y_test , opted_predict, opted_predict_prob)\n",
        "\n",
        "    return temp_comfusion, temp_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "635d220e",
      "metadata": {
        "id": "635d220e"
      },
      "source": [
        "#### 2) Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59951b49",
      "metadata": {
        "id": "59951b49"
      },
      "outputs": [],
      "source": [
        "def DT_model(name, input, output, n_fold, curve, mode):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(input, output)\n",
        "\n",
        "    ## model\n",
        "    model = DecisionTreeClassifier(random_state=1)\n",
        "\n",
        "    ## optimizing hyper-param for model\n",
        "    param = {\n",
        "         'min_impurity_decrease': [0.001, 0.01, 0.001],\n",
        "         'max_depth': range(5, 20, 1),\n",
        "         'min_samples_split': range(2, 100, 10)\n",
        "    }\n",
        "\n",
        "    opted_predict, opted_predict_prob = train_and_calibrate_model(name, model, param, X_train, y_train, X_test, y_test, input, output)\n",
        "\n",
        "    ## Ploting curve\n",
        "    if mode = 1:\n",
        "      plot_curve(input, output, curve, y_test, opted_predict_prob)\n",
        "    elif mode = 2:\n",
        "      plot_curve_(input, output, curve, y_test, opted_predict_prob, name)\n",
        "\n",
        "    ## Get performance metrics\n",
        "    temp_comfusion, temp_result = get_clf_eval(y_test , opted_predict, opted_predict_prob)\n",
        "\n",
        "    return temp_comfusion, temp_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fb2fe78",
      "metadata": {
        "id": "5fb2fe78"
      },
      "source": [
        "#### 3) Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17683845",
      "metadata": {
        "id": "17683845"
      },
      "outputs": [],
      "source": [
        "def RF_model(name, input, output, n_fold, curve, mode):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(input, output)\n",
        "\n",
        "    ## model\n",
        "    model = RandomForestClassifier(n_jobs=-1, random_state=1)\n",
        "\n",
        "    param = {\n",
        "        'n_estimators' : [10, 100],\n",
        "        'max_depth' : [6, 8, 10, 12],\n",
        "        'min_samples_leaf' : [8, 12, 18],\n",
        "        'min_samples_split' : [8, 16, 20]\n",
        "    }\n",
        "\n",
        "    opted_predict, opted_predict_prob = train_and_calibrate_model(name, model, param, X_train, y_train, X_test, y_test, input, output)\n",
        "\n",
        "    ## Ploting curve\n",
        "    if mode = 1:\n",
        "      plot_curve(input, output, curve, y_test, opted_predict_prob)\n",
        "    elif mode = 2:\n",
        "      plot_curve_(input, output, curve, y_test, opted_predict_prob, name)\n",
        "\n",
        "\n",
        "    ## Get performance metrics\n",
        "    temp_comfusion, temp_result = get_clf_eval(y_test , opted_predict, opted_predict_prob)\n",
        "\n",
        "    return temp_comfusion, temp_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a15e12f",
      "metadata": {
        "id": "1a15e12f"
      },
      "source": [
        "#### 4) KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85f65707",
      "metadata": {
        "id": "85f65707"
      },
      "outputs": [],
      "source": [
        "def KNN_model(name, input, output, n_fold, curve, mode):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(input, output)\n",
        "\n",
        "    ## model\n",
        "    model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "    param = {\n",
        "        'n_neighbors' : list(range(1,30)),\n",
        "        'weights' : [\"uniform\", \"distance\"],\n",
        "        'metric' : ['euclidean', 'manhattan', 'minkowski'],\n",
        "        'leaf_size' : range(1, 50, 5)\n",
        "    }\n",
        "\n",
        "    opted_predict, opted_predict_prob = train_and_calibrate_model(name, model, param, X_train, y_train, X_test, y_test, input, output)\n",
        "\n",
        "    ## Ploting curve\n",
        "    if mode = 1:\n",
        "      plot_curve(input, output, curve, y_test, opted_predict_prob)\n",
        "    elif mode = 2:\n",
        "      plot_curve_(input, output, curve, y_test, opted_predict_prob, name)\n",
        "\n",
        "    ## Get performance metrics\n",
        "    temp_comfusion, temp_result = get_clf_eval(y_test , opted_predict, opted_predict_prob)\n",
        "\n",
        "    return temp_comfusion, temp_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ca502af",
      "metadata": {
        "id": "9ca502af"
      },
      "source": [
        "#### 5) XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f01d79a2",
      "metadata": {
        "id": "f01d79a2"
      },
      "outputs": [],
      "source": [
        "def XGB_model(name, input, output, n_fold, curve, mode):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(input, output)\n",
        "\n",
        "    ## model\n",
        "    model = XGBClassifier(booster='gbtree', objective='binary:logistic')\n",
        "\n",
        "    param = {\n",
        "        'n_estimators': [100,200,400,800,1000],\n",
        "        'learning_rate': [0.01,0.05,0.1,0.2,0.3,0.4,0.5],\n",
        "        'gamma': [0,0.01,0.1,0.5,1,2],\n",
        "        'min_child_weight':[1,2,3,4,5]\n",
        "    }\n",
        "\n",
        "    opted_predict, opted_predict_prob = train_and_calibrate_model(name, model, param, X_train, y_train, X_test, y_test, input, output)\n",
        "\n",
        "    ## Ploting curve\n",
        "    if mode = 1:\n",
        "      plot_curve(input, output, curve, y_test, opted_predict_prob)\n",
        "    elif mode = 2:\n",
        "      plot_curve_(input, output, curve, y_test, opted_predict_prob, name)\n",
        "\n",
        "    ## Get performance metrics\n",
        "    temp_comfusion, temp_result = get_clf_eval(y_test , opted_predict, opted_predict_prob)\n",
        "\n",
        "    return temp_comfusion, temp_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f32046a9",
      "metadata": {
        "id": "f32046a9"
      },
      "source": [
        "#### 6) ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "514fe16e",
      "metadata": {
        "id": "514fe16e"
      },
      "outputs": [],
      "source": [
        "def ANN_model(input, output, n_fold, curve):\n",
        "\n",
        "    ## processing data for training/test\n",
        "    features = pd.read_excel(input)\n",
        "    label = pd.read_excel(output)\n",
        "\n",
        "    len_features = int(features.shape[1])\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=42)\n",
        "\n",
        "    y_train = np.ravel(y_train)\n",
        "    y_test = np.ravel(y_test)\n",
        "\n",
        "    smote = SMOTE(random_state=0)\n",
        "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "    ## model\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    model.add(keras.layers.InputLayer(input_shape=(len_features,)))\n",
        "\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model = KerasClassifier(model)\n",
        "\n",
        "    ## optimizing hyper-param for model\n",
        "\n",
        "    # random search\n",
        "    param = {\n",
        "        'batch_size': [16, 32, 64, 128],\n",
        "        'epochs': [10, 20]\n",
        "    }\n",
        "\n",
        "    scoring = ['accuracy']\n",
        "\n",
        "    kfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=1)\n",
        "\n",
        "    random_search = RandomizedSearchCV(estimator=model,\n",
        "                                   param_distributions=param,\n",
        "                                   scoring=scoring,\n",
        "                                   cv=kfold,\n",
        "                                   refit='accuracy',\n",
        "                                   n_jobs=-1,\n",
        "                                   verbose=0)\n",
        "\n",
        "    random_result = random_search.fit(X_train, y_train)\n",
        "\n",
        "    best_model = random_search.best_estimator_\n",
        "    opted_predict = best_model.predict(X_test)\n",
        "    opted_predict_prob = random_search.predict_proba(X_test)[:,1]\n",
        "\n",
        "    ## Ploting curve\n",
        "    plot_curve(input, output, curve, y_test, opted_predict_prob)\n",
        "\n",
        "    ## Get performance metrics\n",
        "    temp_comfusion, temp_result = get_clf_eval(y_test , opted_predict, opted_predict_prob)\n",
        "\n",
        "    return temp_comfusion, temp_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eec655d",
      "metadata": {
        "id": "0eec655d"
      },
      "source": [
        "#### 7) SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e1f791c",
      "metadata": {
        "id": "9e1f791c"
      },
      "outputs": [],
      "source": [
        "def SVM_model(name, input, output, n_fold, curve, mode):\n",
        "\n",
        "    ## processing data for training/test\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(input, output)\n",
        "\n",
        "\n",
        "    ## model\n",
        "    model = SVC(random_state=0, probability=True)\n",
        "\n",
        "    param = {\n",
        "        'C': [0.1,1, 10, 100],\n",
        "        'kernel': ['poly','sigmoid','linear','rbf'],\n",
        "        'gamma': [1,0.1,0.01,0.001]\n",
        "    }\n",
        "\n",
        "    opted_predict, opted_predict_prob = train_and_calibrate_model(name, model, param, X_train, y_train, X_test, y_test, input, output)\n",
        "\n",
        "    ## Ploting curve\n",
        "    if mode = 1:\n",
        "      plot_curve(input, output, curve, y_test, opted_predict_prob)\n",
        "    elif mode = 2:\n",
        "      plot_curve_(input, output, curve, y_test, opted_predict_prob, name)\n",
        "\n",
        "    ## Get performance metrics\n",
        "    temp_comfusion, temp_result = get_clf_eval(y_test , opted_predict, opted_predict_prob)\n",
        "\n",
        "\n",
        "    return temp_comfusion, temp_result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d91cd1b4",
      "metadata": {
        "id": "d91cd1b4"
      },
      "source": [
        "## Execute model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdb44862",
      "metadata": {
        "id": "cdb44862"
      },
      "source": [
        "#### 1) Execute model performance by prediction time windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pfmoUDp7qeX8",
      "metadata": {
        "id": "pfmoUDp7qeX8"
      },
      "outputs": [],
      "source": [
        "#### configure\n",
        "dir_input = [\n",
        "    './df_input/df_2hr.xlsx',\n",
        "    './df_input/df_4hr.xlsx',\n",
        "    './df_input/df_6hr.xlsx',\n",
        "    './df_input/df_8hr.xlsx',\n",
        "    './df_input/df_10hr.xlsx',\n",
        "    './df_input/df_12hr.xlsx'\n",
        "]\n",
        "\n",
        "dir_output = ['./df_output/df_categorical_output_hr/df_categorical_output_60hr.xlsx']\n",
        "\n",
        "n_fold = 5\n",
        "imputation = 'smote'\n",
        "curves = ['roc','pr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84c7a1cc",
      "metadata": {
        "id": "84c7a1cc"
      },
      "outputs": [],
      "source": [
        "## LR, DT, RF, XGB, KNN, SVM\n",
        "## Performance comparison by prediction time windows\n",
        "\n",
        "model = ['LR', 'DT', 'RF', 'XGB', 'KNN', 'SVM']\n",
        "\n",
        "for curve in curves:\n",
        "    execute(dir_input, dir_output, n_fold, imputation, curve, model)\n",
        "    plt.cla()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "273e3d91",
      "metadata": {
        "id": "273e3d91"
      },
      "outputs": [],
      "source": [
        "## ANN\n",
        "\n",
        "curves = ['roc','pr']\n",
        "\n",
        "for curve in curves:\n",
        "    i = 0\n",
        "    total = len(dir_input)*len(dir_output)\n",
        "    df_result = pd.DataFrame(columns = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"ROC AUC\", \"PR AUC\"])\n",
        "\n",
        "    for output in dir_output:\n",
        "        out_ = re.sub(r'[^0-9]', '', output)\n",
        "        idx = {'Accuracy': f'{out_}hr'}\n",
        "        df_result = df_result.append(idx, ignore_index=True)\n",
        "\n",
        "        for input in dir_input:\n",
        "\n",
        "            in_ = re.sub(r'[^0-9]', '', input)\n",
        "            print(f\"{i/total*100}% processing..\")\n",
        "\n",
        "\n",
        "            ## Run\n",
        "            confusion, result = ANN_model(input, output, n_fold, curve)\n",
        "\n",
        "            ## post-process results from model\n",
        "            dic = {}\n",
        "            temp = result.split(', ')\n",
        "\n",
        "            index = 0\n",
        "            for key in df_result.keys():\n",
        "                dic[key] = temp[index]\n",
        "                index += 1\n",
        "\n",
        "            df_result = df_result.append(dic, ignore_index=True)\n",
        "            plt.savefig(f'./result_graph/ANN_{imputation}_{curve}_curve_{out_}hr.png', dpi=300)\n",
        "            i = i + 1\n",
        "\n",
        "        plt.cla()\n",
        "\n",
        "    # export\n",
        "    df_result.to_csv(f'./result_csv/result_ANN__{imputation}_prolonged.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68380570",
      "metadata": {
        "id": "68380570"
      },
      "source": [
        "#### 2) Execute model performances by prediction models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ff4c9b",
      "metadata": {
        "id": "a2ff4c9b"
      },
      "outputs": [],
      "source": [
        "# Performance comparison by prediction model\n",
        "\n",
        "dir_input = './df_input/df_12hr.xlsx'\n",
        "dir_output = './df_output/df_categorical_output_hr/df_categorical_output_60hr.xlsx'\n",
        "\n",
        "models = ['DT','KNN','LR','RF','SVM','XGB', 'ANN']\n",
        "curves = ['roc', 'pr']\n",
        "n_fold = 5\n",
        "imputation = 'smote'\n",
        "\n",
        "for curve in curves:\n",
        "    execute_(dir_input, dir_output, n_fold, imputation, curve, models)\n",
        "    plt.cla()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
